From f3bdfd1626d77a93dd8870cceba04dce0b9ed2ed Mon Sep 17 00:00:00 2001
From: ctang <ctang@cloudera.com>
Date: Sun, 16 Oct 2016 17:29:24 -0400
Subject: [PATCH 683/723] CDH-45810: HIVE-14799: Query operation are not
 thread safe during its cancellation (Chaoyu Tang,
 reivewed by Sergey Shelukhin, Yongzhi Chen)

Change-Id: I3e7f594c592008ef2ba09ec6873eb1f6404a1003
---
 ql/src/java/org/apache/hadoop/hive/ql/Driver.java |  558 ++++++++++++++++-----
 1 file changed, 420 insertions(+), 138 deletions(-)

diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index 2e2bcbc..1d300cb 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -153,13 +153,33 @@
   private int maxthreads;
   private int tryCount = Integer.MAX_VALUE;
 
-  private boolean destroyed;
-
   private String userName;
 
   // For WebUI.  Kept alive after queryPlan is freed.
   private final QueryDisplay queryDisplay = new QueryDisplay();
 
+  // a lock is used for synchronizing the state transition and its associated
+  // resource releases
+  private final ReentrantLock stateLock = new ReentrantLock();
+  private DriverState driverState = DriverState.INITIALIZED;
+
+  private enum DriverState {
+    INITIALIZED,
+    COMPILING,
+    COMPILED,
+    EXECUTING,
+    EXECUTED,
+    // a state that the driver enters after close() has been called to interrupt its running
+    // query in the query cancellation
+    INTERRUPT,
+    // a state that the driver enters after close() has been called to clean the query results
+    // and release the resources after the query has been executed
+    CLOSED,
+    // a state that the driver enters after destroy() is called and it is the end of driver life cycle
+    DESTROYED,
+    ERROR
+  }
+
   private boolean checkConcurrency() {
     boolean supportConcurrency = conf.getBoolVar(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY);
     if (!supportConcurrency) {
@@ -366,8 +386,21 @@ public void restoreSession(QueryState qs) {
    * @return 0 for ok
    */
   public int compile(String command, boolean resetTaskIds) {
+    return compile(command, resetTaskIds, false);
+  }
+
+  // deferClose indicates if the close/destroy should be deferred when the process has been
+  // interrupted, it should be set to true if the compile is called within another method like
+  // runInternal, which defers the close to the called in that method.
+  public int compile(String command, boolean resetTaskIds, boolean deferClose) {
     PerfLogger perfLogger = SessionState.getPerfLogger();
     perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.COMPILE);
+    stateLock.lock();
+    try {
+      driverState = DriverState.COMPILING;
+    } finally {
+      stateLock.unlock();
+    }
 
     command = new VariableSubstitution(new HiveVariableSource() {
       @Override
@@ -385,11 +418,15 @@ public int compile(String command, boolean resetTaskIds) {
       LOG.warn("WARNING! Query command could not be redacted." + e);
     }
 
+    if (isInterrupted()) {
+        return handleInterruption("at beginning of compilation."); //indicate if need clean resource
+    }
+
     //holder for parent command type/string when executing reentrant queries
     QueryState queryState = new QueryState();
 
     if (ctx != null) {
-      close();
+      closeInProcess(false);
     }
 
     if (resetTaskIds) {
@@ -407,7 +444,12 @@ public int compile(String command, boolean resetTaskIds) {
 
     SessionState.get().setupQueryCurrentTimestamp();
 
+    boolean compileError = false;
     try {
+      if (isInterrupted()) {
+        return handleInterruption("before parsing and analysing the query");
+      }
+
       ctx = new Context(conf);
       ctx.setTryCount(getTryCount());
       ctx.setCmd(command);
@@ -461,9 +503,12 @@ public int compile(String command, boolean resetTaskIds) {
       sem.validate();
       perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.ANALYZE);
 
+      if (isInterrupted()) {
+        return handleInterruption("after analyzing query.");
+      }
+
       // get the output schema
       schema = getSchema(sem, conf);
-
       plan = new QueryPlan(queryStr, sem, perfLogger.getStartTime(PerfLogger.DRIVER_RUN), queryId,
         SessionState.get().getCommandType(), schema);
 
@@ -511,6 +556,11 @@ public int compile(String command, boolean resetTaskIds) {
       }
       return 0;
     } catch (Exception e) {
+      if (isInterrupted()) {
+        return handleInterruption("during query compilation: " + e.getMessage());
+      }
+
+      compileError = true;
       ErrorMsg error = ErrorMsg.getErrorMsg(e.getMessage());
       errorMessage = "FAILED: " + e.getClass().getSimpleName();
       if (error != ErrorMsg.GENERIC_ERROR) {
@@ -534,9 +584,49 @@ public int compile(String command, boolean resetTaskIds) {
       perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.COMPILE);
       ImmutableMap<String, Long> compileHMSTimings = dumpMetaCallTimingWithoutEx("compilation");
       queryDisplay.setHmsTimings(QueryDisplay.Phase.COMPILATION, compileHMSTimings);
-
       restoreSession(queryState);
-      LOG.info("Completed compiling command(queryId=" + queryId + "); Time taken: " + duration + " seconds");
+
+      boolean isInterrupted = isInterrupted();
+      if (isInterrupted && !deferClose) {
+        closeInProcess(true);
+      }
+      stateLock.lock();
+      try {
+        if (isInterrupted) {
+          driverState = deferClose ? DriverState.EXECUTING : DriverState.ERROR;
+        } else {
+          driverState = compileError ? DriverState.ERROR : DriverState.COMPILED;
+        }
+      } finally {
+        stateLock.unlock();
+      }
+
+      if (isInterrupted) {
+        LOG.info("Compiling command(queryId=" + queryId + ") has been interrupted after " + duration + " seconds");
+      } else {
+        LOG.info("Completed compiling command(queryId=" + queryId + "); Time taken: " + duration + " seconds");
+      }
+    }
+  }
+
+  private int handleInterruption(String msg) {
+    SQLState = "HY008";  //SQLState for cancel operation
+    errorMessage = "FAILED: command has been interrupted: " + msg;
+    console.printError(errorMessage);
+    return 1000;
+  }
+
+  private boolean isInterrupted() {
+    stateLock.lock();
+    try {
+      if (driverState == DriverState.INTERRUPT) {
+        Thread.currentThread().interrupt();
+        return true;
+      } else {
+        return false;
+      }
+    } finally {
+      stateLock.unlock();
     }
   }
 
@@ -1032,7 +1122,7 @@ private int acquireLocksAndOpenTxn() {
       txnMgr.acquireLocks(plan, ctx, userFromUGI);
 
       return 0;
-    } catch (LockException e) {
+    } catch (Exception e) {
       errorMessage = "FAILED: Error in acquiring locks: " + e.getMessage();
       SQLState = ErrorMsg.findSQLState(e.getMessage());
       downstreamError = e;
@@ -1090,23 +1180,11 @@ private void releaseLocksAndCommitOrRollback(boolean commit)
    * while keeping the result around.
    */
   private void releaseResources() {
+    releasePlan();
+    releaseDriverContext();
     if (SessionState.get() != null) {
       SessionState.get().getLineageState().clear();
     }
-
-    if (plan != null) {
-      fetchTask = plan.getFetchTask();
-      if (fetchTask != null) {
-        fetchTask.setDriverContext(null);
-        fetchTask.setQueryPlan(null);
-      }
-    }
-
-    if (driverCxt != null) {
-      driverCxt.shutdown();
-      driverCxt = null;
-    }
-    plan = null;
   }
 
   @Override
@@ -1122,12 +1200,7 @@ public CommandProcessorResponse run()
 
   public CommandProcessorResponse run(String command, boolean alreadyCompiled)
         throws CommandNeedRetryException {
-    CommandProcessorResponse cpr;
-    try {
-      cpr = runInternal(command, alreadyCompiled);
-    } finally {
-      releaseResources();
-    }
+    CommandProcessorResponse cpr = runInternal(command, alreadyCompiled);
 
     if(cpr.getResponseCode() == 0) {
       return cpr;
@@ -1185,11 +1258,11 @@ public CommandProcessorResponse run(String command, boolean alreadyCompiled)
   }
 
   public CommandProcessorResponse compileAndRespond(String command) {
-    return createProcessorResponse(compileInternal(command));
+    return createProcessorResponse(compileInternal(command, false));
   }
 
   private static final ReentrantLock globalCompileLock = new ReentrantLock();
-  private int compileInternal(String command) {
+  private int compileInternal(String command, boolean deferClose) {
     int ret;
     LOG.debug("Acquire a monitor for compiling query");
     final ReentrantLock compileLock = tryAcquireCompileLock(command);
@@ -1198,7 +1271,7 @@ private int compileInternal(String command) {
     }
 
     try {
-      ret = compile(command);
+      ret = compile(command, true, deferClose);
     } finally {
       compileLock.unlock();
     }
@@ -1263,100 +1336,146 @@ private CommandProcessorResponse runInternal(String command, boolean alreadyComp
     errorMessage = null;
     SQLState = null;
     downstreamError = null;
-
     if (!validateConfVariables()) {
       return createProcessorResponse(12);
     }
 
-    HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(conf, command);
-    // Get all the driver run hooks and pre-execute them.
-    List<HiveDriverRunHook> driverRunHooks;
+    stateLock.lock();
     try {
-      driverRunHooks = getHooks(HiveConf.ConfVars.HIVE_DRIVER_RUN_HOOKS,
-          HiveDriverRunHook.class);
-      for (HiveDriverRunHook driverRunHook : driverRunHooks) {
-          driverRunHook.preDriverRun(hookContext);
+      if (alreadyCompiled) {
+        if (driverState == DriverState.COMPILED) {
+          driverState = DriverState.EXECUTING;
+        } else {
+          errorMessage = "FAILED: Precompiled query has been cancelled or closed.";
+          console.printError(errorMessage);
+          return createProcessorResponse(12);
+        }
+      } else {
+        driverState = DriverState.COMPILING;
       }
-    } catch (Exception e) {
-      errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
-      SQLState = ErrorMsg.findSQLState(e.getMessage());
-      downstreamError = e;
-      console.printError(errorMessage + "\n"
-          + org.apache.hadoop.util.StringUtils.stringifyException(e));
-      return createProcessorResponse(12);
+    } finally {
+      stateLock.unlock();
     }
 
-    // Reset the perf logger
-    PerfLogger perfLogger = SessionState.getPerfLogger(true);
-    perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.DRIVER_RUN);
-    perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TIME_TO_SUBMIT);
+    // a flag that helps to set the correct driver state in finally block by tracking if
+    // the method has been returned by an error or not.
+    boolean isFinishedWithError = true;
+    try {
+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(conf,
+          alreadyCompiled ? ctx.getCmd() : command);
+      // Get all the driver run hooks and pre-execute them.
+      List<HiveDriverRunHook> driverRunHooks;
+      try {
+        driverRunHooks = getHooks(HiveConf.ConfVars.HIVE_DRIVER_RUN_HOOKS,
+            HiveDriverRunHook.class);
+        for (HiveDriverRunHook driverRunHook : driverRunHooks) {
+            driverRunHook.preDriverRun(hookContext);
+        }
+      } catch (Exception e) {
+        errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
+        SQLState = ErrorMsg.findSQLState(e.getMessage());
+        downstreamError = e;
+        console.printError(errorMessage + "\n"
+            + org.apache.hadoop.util.StringUtils.stringifyException(e));
+        return createProcessorResponse(12);
+      }
 
-    int ret;
-    if (!alreadyCompiled) {
-      ret = compileInternal(command);
-      if (ret != 0) {
-        return createProcessorResponse(ret);
+      // Reset the perf logger
+      PerfLogger perfLogger = SessionState.getPerfLogger(true);
+      perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.DRIVER_RUN);
+      perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TIME_TO_SUBMIT);
+
+      int ret;
+      if (!alreadyCompiled) {
+        // compile internal will automatically reset the perf logger
+        ret = compileInternal(command, true);
+        if (ret != 0) {
+          return createProcessorResponse(ret);
+        }
       }
-    }
 
-    // the reason that we set the txn manager for the cxt here is because each
-    // query has its own ctx object. The txn mgr is shared across the
-    // same instance of Driver, which can run multiple queries.
-    ctx.setHiveTxnManager(SessionState.get().getTxnMgr());
+      // the reason that we set the txn manager for the cxt here is because each
+      // query has its own ctx object. The txn mgr is shared across the
+      // same instance of Driver, which can run multiple queries.
+      ctx.setHiveTxnManager(SessionState.get().getTxnMgr());
 
-    if (requiresLock()) {
-      ret = acquireLocksAndOpenTxn();
-      if (ret != 0) {
-        try {
-          releaseLocksAndCommitOrRollback(false);
-        } catch (LockException e) {
-          // Not much to do here
+      if (requiresLock()) {
+        // a checkpoint to see if the thread is interrupted or not before an expensive operation
+        if (isInterrupted()) {
+          ret = handleInterruption("at acquiring the lock.");
+        } else {
+          ret = acquireLocksAndOpenTxn();
+        }
+        if (ret != 0) {
+          try {
+            releaseLocksAndCommitOrRollback(false);
+          } catch (LockException e) {
+            // Not much to do here
+          }
+          return createProcessorResponse(ret);
         }
-        return createProcessorResponse(ret);
       }
-    }
-    ret = execute();
-    if (ret != 0) {
+
+      ret = execute(true);
+      if (ret != 0) {
+	    //if needRequireLock is false, the release here will do nothing because there is no lock
+	    try {
+	      releaseLocksAndCommitOrRollback(false);
+	    } catch (LockException e) {
+	      // Nothing to do here
+	    }
+	    return createProcessorResponse(ret);
+      }
+
       //if needRequireLock is false, the release here will do nothing because there is no lock
       try {
-        releaseLocksAndCommitOrRollback(false);
+        releaseLocksAndCommitOrRollback(true);
       } catch (LockException e) {
-        // Nothing to do here
+        errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
+        SQLState = ErrorMsg.findSQLState(e.getMessage());
+        downstreamError = e;
+        console.printError(errorMessage + "\n"
+            + org.apache.hadoop.util.StringUtils.stringifyException(e));
+        return createProcessorResponse(12);
       }
-      return createProcessorResponse(ret);
-    }
-
-    //if needRequireLock is false, the release here will do nothing because there is no lock
-    try {
-      releaseLocksAndCommitOrRollback(true);
-    } catch (LockException e) {
-      errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
-      SQLState = ErrorMsg.findSQLState(e.getMessage());
-      downstreamError = e;
-      console.printError(errorMessage + "\n"
-          + org.apache.hadoop.util.StringUtils.stringifyException(e));
-      return createProcessorResponse(12);
-    }
 
-    perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.DRIVER_RUN);
-    queryDisplay.setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());
-    queryDisplay.setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());
+      perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.DRIVER_RUN);
+      queryDisplay.setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());
+      queryDisplay.setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());
 
-    // Take all the driver run hooks and post-execute them.
-    try {
-      for (HiveDriverRunHook driverRunHook : driverRunHooks) {
-          driverRunHook.postDriverRun(hookContext);
+      // Take all the driver run hooks and post-execute them.
+      try {
+        for (HiveDriverRunHook driverRunHook : driverRunHooks) {
+            driverRunHook.postDriverRun(hookContext);
+        }
+      } catch (Exception e) {
+        errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
+        SQLState = ErrorMsg.findSQLState(e.getMessage());
+        downstreamError = e;
+        console.printError(errorMessage + "\n"
+            + org.apache.hadoop.util.StringUtils.stringifyException(e));
+        return createProcessorResponse(12);
+      }
+      isFinishedWithError = false;
+      return createProcessorResponse(ret);
+    } finally {
+      if (isInterrupted()) {
+        closeInProcess(true);
+      } else {
+        // only release the related resources ctx, driverContext as normal
+        releaseResources();
+      }
+      stateLock.lock();
+      try {
+        if (driverState == DriverState.INTERRUPT) {
+          driverState = DriverState.ERROR;
+        } else {
+          driverState = isFinishedWithError ? DriverState.ERROR : DriverState.EXECUTED;
+        }
+      } finally {
+        stateLock.unlock();
       }
-    } catch (Exception e) {
-      errorMessage = "FAILED: Hive Internal Error: " + Utilities.getNameMessage(e);
-      SQLState = ErrorMsg.findSQLState(e.getMessage());
-      downstreamError = e;
-      console.printError(errorMessage + "\n"
-          + org.apache.hadoop.util.StringUtils.stringifyException(e));
-      return createProcessorResponse(12);
     }
-
-    return createProcessorResponse(ret);
   }
 
   private boolean requiresLock() {
@@ -1440,18 +1559,41 @@ private boolean validateConfVariables() {
   }
 
   public int execute() throws CommandNeedRetryException {
+    return execute(false);
+  }
+
+  public int execute(boolean deferClose) throws CommandNeedRetryException {
     PerfLogger perfLogger = SessionState.getPerfLogger();
     perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.DRIVER_EXECUTE);
     boolean noName = StringUtils.isEmpty(conf.getVar(HiveConf.ConfVars.HADOOPJOBNAME));
     int maxlen = conf.getIntVar(HiveConf.ConfVars.HIVEJOBNAMELENGTH);
 
-    String queryId = plan.getQueryId();
+    String queryId = conf.getVar(HiveConf.ConfVars.HIVEQUERYID);
     // Get the query string from the conf file as the compileInternal() method might
     // hide sensitive information during query redaction.
     String queryStr = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYSTRING);
 
+    stateLock.lock();
+    try {
+      // if query is not in compiled state, or executing state which is carried over from
+      // a combined compile/execute in runInternal, throws the error
+      if (driverState != DriverState.COMPILED &&
+          driverState != DriverState.EXECUTING) {
+        SQLState = "HY008";
+        errorMessage = "FAILED: query " + queryStr + " has " +
+            (driverState == DriverState.INTERRUPT ? "been cancelled" : "not been compiled.");
+        console.printError(errorMessage);
+        return 1000;
+      } else {
+        driverState = DriverState.EXECUTING;
+      }
+    } finally {
+      stateLock.unlock();
+    }
+
     maxthreads = HiveConf.getIntVar(conf, HiveConf.ConfVars.EXECPARALLETHREADNUMBER);
 
+    boolean executionError = false;
     try {
       LOG.info("Executing command(queryId=" + queryId + "): " + queryStr);
       // compile and execute can get called from different threads in case of HS2
@@ -1508,11 +1650,13 @@ public int execute() throws CommandNeedRetryException {
       // At any time, at most maxthreads tasks can be running
       // The main thread polls the TaskRunners to check if they have finished.
 
+      if (isInterrupted()) {
+        return handleInterruption("before running tasks.");
+      }
       DriverContext driverCxt = new DriverContext(ctx);
       driverCxt.prepare(plan);
 
       ctx.setHDFSCleanup(true);
-
       this.driverCxt = driverCxt; // for canceling the query (should be bound to session?)
 
       SessionState.get().setMapRedStats(new LinkedHashMap<String, MapRedStats>());
@@ -1530,7 +1674,7 @@ public int execute() throws CommandNeedRetryException {
       perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.TIME_TO_SUBMIT);
       perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.RUN_TASKS);
       // Loop while you either have tasks running, or tasks queued up
-      while (!destroyed && driverCxt.isRunning()) {
+      while (driverCxt.isRunning()) {
 
         // Launch upto maxthreads tasks
         Task<? extends Serializable> task;
@@ -1554,6 +1698,9 @@ public int execute() throws CommandNeedRetryException {
         TaskResult result = tskRun.getTaskResult();
 
         int exitVal = result.getExitVal();
+        if (isInterrupted()) {
+          return handleInterruption("when checking the execution result.");
+        }
         if (exitVal != 0) {
           if (tsk.ifRetryCmdWhenFail()) {
             driverCxt.shutdown();
@@ -1665,9 +1812,16 @@ public int execute() throws CommandNeedRetryException {
             String.valueOf(0));
         SessionState.get().getHiveHistory().printRowCount(queryId);
       }
+      releasePlan(plan);
     } catch (CommandNeedRetryException e) {
+      executionError = true;
       throw e;
     } catch (Exception e) {
+      executionError = true;
+      if (isInterrupted()) {
+        return handleInterruption("during query execution: \n" + e.getMessage());
+      }
+
       ctx.restoreOriginalTracker();
       if (SessionState.get() != null) {
         SessionState.get().getHiveHistory().setQueryProperty(queryId, Keys.QUERY_RET_CODE,
@@ -1701,22 +1855,56 @@ public int execute() throws CommandNeedRetryException {
         }
         console.printInfo("Total MapReduce CPU Time Spent: " + Utilities.formatMsecToStr(totalCpu));
       }
-      LOG.info("Completed executing command(queryId=" + queryId + "); Time taken: " + duration + " seconds");
-    }
-    plan.setDone();
-
-    if (SessionState.get() != null) {
+      boolean isInterrupted = isInterrupted();
+      if (isInterrupted && !deferClose) {
+        closeInProcess(true);
+      }
+      stateLock.lock();
       try {
-        SessionState.get().getHiveHistory().logPlanProgress(plan);
-      } catch (Exception e) {
-        // ignore
+        if (isInterrupted) {
+          if (!deferClose) {
+            driverState = DriverState.ERROR;
+          }
+        } else {
+          driverState = executionError ? DriverState.ERROR : DriverState.EXECUTED;
+        }
+      } finally {
+        stateLock.unlock();
       }
+      if (isInterrupted) {
+        LOG.info("Executing command(queryId=" + queryId + ") has been interrupted after " + duration + " seconds");
+      } else {
+        LOG.info("Completed executing command(queryId=" + queryId + "); Time taken: " + duration + " seconds");
+      }
+    }
+
+    if (console != null) {
+      console.printInfo("OK");
     }
-    console.printInfo("OK");
 
     return (0);
   }
 
+  private void releasePlan(QueryPlan plan) {
+    // Plan maybe null if Driver.close is called in another thread for the same Driver object
+    stateLock.lock();
+    try {
+      if (plan != null) {
+        plan.setDone();
+        if (SessionState.get() != null) {
+          try {
+            SessionState.get().getHiveHistory().logPlanProgress(plan);
+          } catch (Exception e) {
+            // Log and ignore
+            LOG.warn("Could not log query plan progress", e);
+          }
+        }
+      }
+    } finally {
+      stateLock.unlock();
+    }
+  }
+
   private void setErrorMsgAndDetail(int exitVal, Throwable downstreamError, Task tsk) {
     this.downstreamError = downstreamError;
     errorMessage = "FAILED: Execution Error, return code " + exitVal + " from " + tsk.getClass().getName();
@@ -1790,9 +1978,10 @@ public boolean isFetchingTable() {
 
   @SuppressWarnings("unchecked")
   public boolean getResults(List res) throws IOException, CommandNeedRetryException {
-    if (destroyed) {
-      throw new IOException("FAILED: Operation cancelled");
+    if (driverState == DriverState.DESTROYED || driverState == DriverState.CLOSED) {
+      throw new IOException("FAILED: query has been cancelled, closed, or destroyed.");
     }
+
     if (isFetchingTable()) {
       fetchTask.setMaxRows(maxRows);
       return fetchTask.fetch(res);
@@ -1845,6 +2034,9 @@ public boolean getResults(List res) throws IOException, CommandNeedRetryExceptio
   }
 
   public void resetFetch() throws IOException {
+    if (driverState == DriverState.DESTROYED || driverState == DriverState.CLOSED) {
+      throw new IOException("FAILED: driver has been cancelled, closed or destroyed.");
+    }
     if (isFetchingTable()) {
       try {
         fetchTask.clearFetch();
@@ -1867,21 +2059,39 @@ public void setTryCount(int tryCount) {
     this.tryCount = tryCount;
   }
 
-  public int close() {
+  // DriverContext could be released in the query and close processes at same
+  // time, which needs to be thread protected.
+  private void releaseDriverContext() {
+    stateLock.lock();
     try {
-      try {
-        releaseResources();
-      } catch (Exception e) {
-        LOG.info("Exception while releasing resources", e);
+      if (driverCxt != null) {
+        driverCxt.shutdown();
+        driverCxt = null;
       }
-      if (fetchTask != null) {
-        try {
-          fetchTask.clearFetch();
-        } catch (Exception e) {
-          LOG.debug(" Exception while clearing the Fetch task ", e);
+    } catch (Exception e) {
+      LOG.debug("Exception while shutting down the task runner", e);
+    } finally {
+      stateLock.unlock();
+    }
+  }
+
+  private void releasePlan() {
+    try {
+      if (plan != null) {
+        fetchTask = plan.getFetchTask();
+        if (fetchTask != null) {
+          fetchTask.setDriverContext(null);
+          fetchTask.setQueryPlan(null);
         }
-        fetchTask = null;
       }
+      plan = null;
+    } catch (Exception e) {
+      LOG.debug("Exception while clearing the Fetch task", e);
+    }
+  }
+
+  private void releaseContext() {
+    try {
       if (ctx != null) {
         ctx.clear();
         if (ctx.getHiveLocks() != null) {
@@ -1890,27 +2100,98 @@ public int close() {
         }
         ctx = null;
       }
-      if (null != resStream) {
+    } catch (Exception e) {
+      LOG.debug("Exception while clearing the context ", e);
+    }
+  }
+
+  private void releaseResStream() {
+    try {
+      if (resStream != null) {
+        ((FSDataInputStream) resStream).close();
+        resStream = null;
+      }
+    } catch (Exception e) {
+      LOG.debug(" Exception while closing the resStream ", e);
+    }
+  }
+
+  private void releaseFetchTask() {
+    try {
+      if (fetchTask != null) {
+        fetchTask.clearFetch();
+        fetchTask = null;
+      }
+    } catch (Exception e) {
+      LOG.debug(" Exception while clearing the FetchTask ", e);
+    }
+  }
+  // Close and release resources within a running query process. Since it runs under
+  // driver state COMPILING, EXECUTING or INTERRUPT, it would not have race condition
+  // with the releases probably running in the other closing thread.
+  private int closeInProcess(boolean destroyed) {
+    releaseDriverContext();
+    releasePlan();
+    releaseFetchTask();
+    releaseResStream();
+    releaseContext();
+    if (SessionState.get() != null) {
+      SessionState.get().getLineageState().clear();
+    }
+    if(destroyed) {
+      if (!hiveLocks.isEmpty()) {
         try {
-          ((FSDataInputStream) resStream).close();
-        } catch (Exception e) {
-          LOG.debug(" Exception while closing the resStream ", e);
+          releaseLocksAndCommitOrRollback(false);
+        } catch (LockException e) {
+          LOG.warn("Exception when releasing locking in destroy: " +
+              e.getMessage());
         }
       }
-    } catch (Exception e) {
-      console.printError("FAILED: Hive Internal Error: " + Utilities.getNameMessage(e) + "\n"
-          + org.apache.hadoop.util.StringUtils.stringifyException(e));
-      return 13;
     }
+    return 0;
+  }
 
+  // is called to stop the query if it is running, clean query results, and release resources.
+  public int close() {
+    stateLock.lock();
+    try {
+      releaseDriverContext();
+      if (driverState == DriverState.COMPILING ||
+          driverState == DriverState.EXECUTING ||
+          driverState == DriverState.INTERRUPT) {
+        driverState = DriverState.INTERRUPT;
+        return 0;
+      }
+      releasePlan();
+      releaseFetchTask();
+      releaseResStream();
+      releaseContext();
+      driverState = DriverState.CLOSED;
+    } finally {
+      stateLock.unlock();
+    }
+    if (SessionState.get() != null) {
+      SessionState.get().getLineageState().clear();
+    }
     return 0;
   }
 
+  // is usually called after close() to commit or rollback a query and end the driver life cycle.
+  // do not understand why it is needed and wonder if it could be combined with close.
   public void destroy() {
-    if (destroyed) {
-      return;
+    stateLock.lock();
+    try {
+      // in the cancel case where the driver state is INTERRUPTED, destroy will be deferred to
+      // the query process
+      if (driverState == DriverState.DESTROYED ||
+          driverState == DriverState.INTERRUPT) {
+        return;
+      } else {
+        driverState = DriverState.DESTROYED;
+      }
+    } finally {
+      stateLock.unlock();
     }
-    destroyed = true;
     if (!hiveLocks.isEmpty()) {
       try {
         releaseLocksAndCommitOrRollback(false);
@@ -1921,6 +2202,7 @@ public void destroy() {
     }
   }
 
+
   public org.apache.hadoop.hive.ql.plan.api.Query getQueryPlan() throws IOException {
     return plan.getQueryPlan();
   }
-- 
1.7.9.5

